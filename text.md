# CycleGAN - это весело!

В этой статье мы хотим рассказать про достаточно новый метод в машинном обучении, который был предложен в статье ["Unpaired Image-to-Image Translation
using Cycle-Consistent Adversarial Networks"](https://arxiv.org/pdf/1703.10593.pdf) группой авторов из UC Berkeley под предводительством великого [Алеши Эфроса](http://people.eecs.berkeley.edu/~efros/). 
(который, кстати в начале июня даже приезжал рассказывать про эту работу в Москву, чему многие счастливчики были свидетелями). 
Почему мы так громко заявляем, что это новый метод, а не просто yet another GAN (сослаться на пашину статью)? У нас есть на то некоторые основания, да хотя бы взгляните на эти картинки:

Но обо всем по порядку, двинемся по плану:
1. Формулировка задачи и предшествующие работы.
3. Как это работает.
4. Как это можно использовать.

## Формулировка задачи и предшествующие работы
Итак, разберем по кусочкам название статьи. Начнем с Image-to-Image translation. В нашем случае идет речь не про произвольное преобразование 
картинки в картинку, а особый класс преобразований, когда оба изображения - и исходное и результирующее - являются разными отображениями 
одной действительности. Отличным примером служит уже многим известный artistic style transfer - в данном случае разные отображения - это, например, отображение 
через оптический прибор, фотоаппарат, и через призму воображения художника какой-то одной сцены. В качестве отображения подходит даже карандашный набросок.
Другой пример - разные слои на карте, спутник или схема. Фотография одного места днем или ночью, зимой или летом - это опять как бы разный рендеринг одной действительности,
а значит, мы хотим уметь (и умеем) такое преобразование совершать.

Вернемся теперь к первому слову названия - unpaired, здесь наиболее точно можно перевести как "в отсутствие парных примеров". Основной работой, поверх которой построена
данная, является статья [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf)

